# -*- coding: utf-8 -*-
"""iPOD_ROM_DWR_error.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b3W0mbgFdQpc3brRnt-NYXOygyqLP9xH

# Incremental Proper Orthogonality Decomposition based Reduced Order Modeling (iPOD-ROM) with DWR error estimator

In this notebook, we demonstrate how the incremental Proper Orthogonality Decomposition (iPOD) can be used for reduced order modeling. This gives us a barebones implementation of the [MORe DWR paper](https://doi.org/10.48550/arXiv.2304.01140) by Fischer et al. The major difference to this publication is that here we will not use space-time finite elements, but we now use a DWR error estimator for 1 parent slab.
"""
import math
import os
import time

import dolfin
import matplotlib.pyplot as plt
import numpy as np
import scipy
from fenics import *
from matplotlib.animation import FuncAnimation
from matplotlib.ticker import FormatStrFormatter, MaxNLocator
from petsc4py import PETSc

PLOT = False

"""## Routine for incremental Proper Orthogonal Decomposition (iPOD)"""


def iPOD(
    POD,  # POD basis
    snapshot,  # new snapshot to be added to POD basis
    bunch_matrix,  # bunch matrix
    bunch_size,  # desired size of bunch matrix
    singular_values,  # singular values of POD basis
    total_energy,  # total energy of POD basis
    energy_content,  # desired energy content
):
    if bunch_matrix.shape[1] == 0:
        # initialize bunch matrix if empty
        # np.empty([np.shape(snapshot)[0], 0])
        bunch_matrix = snapshot.reshape(-1, 1)
    else:
        # concatenate new snapshot to bunch matrix
        bunch_matrix = np.hstack((bunch_matrix, snapshot.reshape(-1, 1)))

    # add energy of new snapshot to total energy
    total_energy += np.dot((snapshot), (snapshot))

    # check bunch_matrix size to decide if to update POD
    if bunch_matrix.shape[1] == bunch_size:
        # initialize POD with first bunch matrix
        if POD.shape[1] == 0:
            POD, S, _ = scipy.linalg.svd(bunch_matrix, full_matrices=False)

            # compute the number of POD modes to be kept
            r = 0
            while (np.dot(S[0:r], S[0:r]) <= energy_content * total_energy) and (
                r <= np.shape(S)[0]
            ):
                r += 1

            singular_values = S[0:r]
            POD = POD[:, 0:r]
        # update POD with  bunch matrix
        else:
            M = np.dot(POD.T, bunch_matrix)
            P = bunch_matrix - np.dot(POD, M)

            Q_p, R_p = scipy.linalg.qr(P, mode="economic")
            Q_q = np.hstack((POD, Q_p))

            S0 = np.vstack(
                (
                    np.diag(singular_values),
                    np.zeros((np.shape(R_p)[0], np.shape(singular_values)[0])),
                )
            )
            MR_p = np.vstack((M, R_p))
            K = np.hstack((S0, MR_p))

            # check the orthogonality of Q_q heuristically
            if np.inner(Q_q[:, 0], Q_q[:, -1]) >= 1e-10:
                Q_q, R_q = scipy.linalg.qr(Q_q, mode="economic")
                K = np.matmul(R_q, K)

            # inner SVD of K
            U_k, S_k, _ = scipy.linalg.svd(K, full_matrices=False)

            # compute the number of POD modes to be kept
            r = POD.shape[1] + 1
            while (np.dot(S_k[0:r], S_k[0:r]) <= energy_content * total_energy) and (
                r < np.shape(S_k)[0]
            ):
                r += 1

            singular_values = S_k[0:r]
            POD = np.matmul(Q_q, U_k[:, 0:r])

        # empty bunch matrix after update
        bunch_matrix = np.empty([np.shape(bunch_matrix)[0], 0])

    return {
        "POD": POD,
        "bunch_matrix": bunch_matrix,
        "singular_values": singular_values,
        "total_energy": total_energy,
    }


# Source: https://github.com/mathmerizing/POD-ROM/blob/main/POD_Fenics.ipynb


# start time
t = 0.0
# end time
T = 1.0
# time step size
Δt = 0.01

# defining the mesh
nx = ny = 20
mesh = UnitSquareMesh(nx, ny)
# visualize the triangulation
if PLOT:
    plot(mesh)
    plt.show()

V = FunctionSpace(mesh, "P", 1)
bc = DirichletBC(V, Constant(0.0), lambda _, on_boundary: on_boundary)

# initial condition
u_0 = Constant(0.0)
# u_n: solution from last time step
u_n = interpolate(u_0, V)

# Define variational problem
u = TrialFunction(V)
v = TestFunction(V)

# mass matrix
M = assemble(u * v * dx)

# Laplace matrix
K = assemble(dot(grad(u), grad(v)) * dx)

# right hand side function


class RHSExpression(UserExpression):
    _t = 0.0

    def set_time(self, t):
        self._t = t

    def eval_cell(self, value, x, ufc_cell):
        if (x[0] - 0.5 - 0.25 * np.cos(2.0 * np.pi * self._t)) ** 2 + (
            x[1] - 0.5 - 0.25 * np.sin(2.0 * np.pi * self._t)
        ) ** 2 < 0.125**2:
            value[0] = np.sin(4.0 * np.pi * self._t)
        else:
            value[0] = 0.0

    def value_shape(self):
        return ()  # scalar function


rhs_func = RHSExpression()

# system matrix
system_matrix = M + Δt * K

# right hand side matrix
rhs_matrix = M

# prepare dual matrices
dual_system_matrix = system_matrix.copy()
dual_rhs_matrix = rhs_matrix.copy()

# number of snapshots
n = int(math.ceil((T - t) / Δt)) + 1

# number of degrees of freedom
m = V.dim()

# snapshot matrix
Y = np.zeros((m, n))
RHS = np.zeros((m, n))

# store initial condition in snapshot matrix
Y[:, 0] = u_n.vector().get_local()
rhs_func.set_time(t)
RHS[:, 0] = np.array(assemble(rhs_func * v * dx))

print("Precompute RHS...")
start_execution = time.time()
# precompute the right hand side
n = 1
while t + Δt <= T + 1e-8:
    # Update current time
    t += Δt
    rhs_func.set_time(t)
    RHS[:, n] = np.array(assemble(rhs_func * v * dx))
    n += 1
print(f"Done [{time.time()-start_execution:.2f} s]")

# Solve timestep with FOM


def solve_primal_FOM_timestep(u_n_vector, rhs_vector):
    A = system_matrix
    # reinit solution vectors
    u = Function(V)
    u_n = Function(V)
    u_n.vector().set_local(u_n_vector[:])
    # Compute RHS
    b = u_n.vector().copy()
    rhs_matrix.mult(u_n.vector(), b)
    # Add force terms
    b[:] += rhs_vector  # RHS[:, n]
    # Apply boundary conditions
    bc.apply(A, b)
    # Solve linear system
    solve(A, u.vector(), b)
    return u.vector().get_local()


# Solve dual timestep with FOM


def solve_dual_FOM_timestep(u_n_vector, z_n_vector):
    A = dual_system_matrix
    # reinit solution vectors
    u_n = Function(V)
    u_n.vector().set_local(u_n_vector[:])
    z_n = Function(V)
    z_n.vector().set_local(z_n_vector[:])
    z = Function(V)
    # compute dual RHS from primal solution and previous dual solution
    b = z_n.vector().copy()
    b2 = z_n.vector().copy()
    dual_rhs_matrix.mult(z_n.vector(), b)
    dual_rhs_matrix.mult(u_n.vector(), b2)
    b[:] += 2 * Δt * b2[:]
    # Apply boundary conditions
    bc.apply(A, b)
    # Solve linear system
    solve(A, z.vector(), b)
    return z.vector().get_local()


# Time-stepping
u = Function(V)  # u_{n+1}: current solution

functional_values_FOM = np.zeros((n - 1,))

print("Solving FOM...")
start_execution = time.time()

# start time
t = 0.0

n = 1
while t + Δt <= T + 1e-8:
    # Update current time
    t += Δt

    # Store solution in snapshot matrix
    Y[:, n] = solve_primal_FOM_timestep(Y[:, n - 1], RHS[:, n])
    u.vector().set_local(Y[:, n])

    # Compute functional value
    # NOTE: using matrix-vector product instead of assemble() for efficiency
    tmp = u.vector().copy()
    rhs_matrix.mult(u.vector(), tmp)
    functional_values_FOM[n - 1] = Δt * np.dot(u.vector().get_local(), tmp.get_local())

    n += 1
execution_time_FOM = time.time() - start_execution
print(f"Done [{execution_time_FOM:.2f} s]")

"""## Solving the incremental Reduced Order Model
To make the computations cheaper, we now want to replace the large linear equation system from the finite element simulations with a reduced linear system of size $r \\ll m$. A popular approach for this is Proper Orthogonal Decomposition (POD) based reduced order modeling (ROM), where one tries to find a new basis from the snapshots of the high fidelity simulation and then carries out all remaining simulations in this low dimensional function space. A mathematically rigorous overview of this topic can be found in <a href="http://www.math.uni-konstanz.de/numerik/personen/volkwein/teaching/POD-Book.pdf">Prof. Volkwein's lecture notes</a> or in [this GitHub repository](https://github.com/mathmerizing/POD-ROM). Here, we now do things slightly differently and update the POD basis on-the-fly. This has been described in Section 4.2.1 of the [MORe DWR paper](https://doi.org/10.48550/arXiv.2304.01140).
"""

# change from the FOM to the POD basis


def reduce_matrix(matrix, pod_basis_left, pod_basis_right=None, use_petsc=True):
    if pod_basis_right is None:
        pod_basis_right = pod_basis_left

    # use PETSc for matrix multiplication, since it uses the sparse matrix and
    # the numpy alternative works with the dense matrix which is more
    # expensive
    if use_petsc:
        basis_left = PETSc.Mat().createDense(pod_basis_left.shape, array=pod_basis_left)
        basis_left.transpose()
        basis_right = PETSc.Mat().createDense(pod_basis_right.shape, array=pod_basis_right)
        _matrix = as_backend_type(matrix).mat()
        return Matrix(PETScMatrix(basis_left.matMult(_matrix.matMult(basis_right)))).array()
    else:
        return np.dot(np.dot(pod_basis_left.T, matrix.array()), pod_basis_right)


def reduce_vector(vector, pod_basis):
    return np.dot(pod_basis.T, vector)


# change from POD to FOM basis


def project_vector(vector, pod_basis):
    return np.dot(pod_basis, vector)


print("Solving MORe DWR...")
start_execution = time.time()

# Initialize POD setting
POD_primal_dict = {
    "POD": np.empty([0, 0]),
    "singular_values": np.empty([0]),
    "total_energy": 0.0,
    "bunch_matrix": np.empty([0, 0]),
}

POD_dual_dict = {
    "POD": np.empty([0, 0]),
    "singular_values": np.empty([0]),
    "total_energy": 0.0,
    "bunch_matrix": np.empty([0, 0]),
}

BUNCH_SIZE = 1
ENERGY_CONTENT = 0.999999
DUAL_ENERGY_CONTENT = 0.999999

# maximal allowed error
MAX_ERROR = 1e-4

# create an initial POD basis from the first FOM snapshot
POD_primal_dict = iPOD(
    **POD_primal_dict, snapshot=Y[:, 1], bunch_size=BUNCH_SIZE, energy_content=ENERGY_CONTENT
)

for i in range(5):
    POD_dual_dict = iPOD(
        **POD_dual_dict,
        snapshot=Y[:, -i],
        bunch_size=BUNCH_SIZE,
        energy_content=DUAL_ENERGY_CONTENT,
    )

# prepare primal matrices
RHS_reduced_primal = np.dot(POD_primal_dict["POD"].T, RHS)
reduced_system_matrix = reduce_matrix(system_matrix, POD_primal_dict["POD"])
reduced_rhs_matrix = reduce_matrix(rhs_matrix, POD_primal_dict["POD"])

# prepare reduced dual matrices
reduced_dual_system_matrix = reduce_matrix(dual_system_matrix, POD_dual_dict["POD"])
reduced_dual_rhs_matrix = reduce_matrix(dual_rhs_matrix, POD_dual_dict["POD"])

# prepare dual+primal reduced matrices for error computations
RHS_reduced_dual = np.dot(POD_dual_dict["POD"].T, RHS)
# dualprim := dual - primal -> left multiply with dual POD transpose and
# right multiply with primal POD
dualprim_reduced_system_matrix = reduce_matrix(
    system_matrix, POD_dual_dict["POD"], POD_primal_dict["POD"]
)
dualprim_reduced_rhs_matrix = reduce_matrix(
    rhs_matrix, POD_dual_dict["POD"], POD_primal_dict["POD"]
)

z = TrialFunction(V)


def solve_primal_ROM(reduced_system_matrix, reduced_rhs_matrix, POD, RHS_reduced, u_0_ROM):
    # print("  INFO: Solve primal ROM")

    # start time
    t = 0.0

    # u_n: solution from last time step
    u_n_ROM = u_0_ROM.copy()

    # primal POD size
    r = POD.shape[1]

    # number of snapshots
    n = int(math.ceil((T - t) / Δt)) + 1

    # snapshot matrix
    Y_ROM = np.zeros((r, n))

    # store initial condition in snapshot matrix
    Y_ROM[:, 0] = u_n_ROM[:]

    # Time-stepping
    n = 1

    while t + Δt <= T + 1e-8:
        # Update current time
        t += Δt

        # 1. Solve timestep with ROM
        u_n_ROM = np.linalg.solve(
            reduced_system_matrix, np.dot(reduced_rhs_matrix, u_n_ROM) + RHS_reduced[:, n]
        )

        # Store solution in snapshot matrix
        Y_ROM[:, n] = u_n_ROM[:]
        n += 1

    return Y_ROM


def solve_dual_ROM(
    reduced_dual_system_matrix,
    reduced_dual_rhs_matrix,
    dualprim_reduced_rhs_matrix,
    POD_dual,
    Y_ROM,
    z_T_ROM,
):
    # print("  INFO: Solve dual ROM")

    # final time
    t = T

    # z_n: solution from next time step (running backward in time)
    z_n_ROM = z_T_ROM.copy()

    # dual POD size
    r = POD_dual.shape[1]

    # number of snapshots
    n = int(math.ceil((T - 0.0) / Δt)) + 1

    # dual snapshot matrix
    Y_ROM_dual = np.zeros((r, n))

    # store final condition in snapshot matrix
    Y_ROM_dual[:, n - 1] = z_n_ROM[:]

    # Time-stepping
    n -= 2

    while t - Δt >= 0.0 - 1e-8:
        # Update current time
        t -= Δt

        # 1. Solve timestep with ROM
        u_n_ROM = Y_ROM[:, n]

        z_n_ROM = np.linalg.solve(
            reduced_dual_system_matrix,
            np.dot(reduced_dual_rhs_matrix, z_n_ROM)
            + 2 * Δt * np.dot(dualprim_reduced_rhs_matrix, u_n_ROM),
        )

        # Store solution in snapshot matrix
        Y_ROM_dual[:, n] = z_n_ROM[:]
        n -= 1

    return Y_ROM_dual


max_rel_error = None
max_rel_error_iteration = []
REL_ERROR_TOL = 0.01
MAX_ITERATIONS = 50  # 100
iteration = 1
N_SNAPSHOTS = int(math.ceil((T - 0.0) / Δt)) + 1

while iteration <= MAX_ITERATIONS:
    # print(f"{iteration}. Iteration:")

    # 1. Solve primal ROM
    u_0 = interpolate(Constant(0.0), V)
    u_0_ROM = reduce_vector(u_0.vector().get_local(), POD_primal_dict["POD"])
    Y_ROM = solve_primal_ROM(
        reduced_system_matrix,
        reduced_rhs_matrix,
        POD_primal_dict["POD"],
        RHS_reduced_primal,
        u_0_ROM,
    )

    # 2. Solve dual ROM
    z_T = interpolate(Constant(0.0), V)
    z_T_ROM = reduce_vector(z_T.vector().get_local(), POD_dual_dict["POD"])
    Y_ROM_dual = solve_dual_ROM(
        reduced_dual_system_matrix,
        reduced_dual_rhs_matrix,
        dualprim_reduced_rhs_matrix,
        POD_dual_dict["POD"],
        Y_ROM,
        z_T_ROM,
    )

    errors = np.zeros((N_SNAPSHOTS - 1,))
    functional_values = np.zeros((N_SNAPSHOTS - 1,))
    for i in range(1, N_SNAPSHOTS):
        # 3a) compute DWR error estimator
        errors[i - 1] = np.dot(
            Y_ROM_dual[:, i - 1],
            -np.dot(dualprim_reduced_system_matrix, Y_ROM[:, i])
            + np.dot(dualprim_reduced_rhs_matrix, Y_ROM[:, i - 1])
            + RHS_reduced_dual[:, i],
        )

        # 3b) evaluate goal functional
        functional_values[i - 1] = Δt * np.dot(Y_ROM[:, i], np.dot(reduced_rhs_matrix, Y_ROM[:, i]))

    relative_errors = errors / (errors + functional_values)

    i_max = np.argmax(np.abs(relative_errors))
    max_rel_error = np.abs(relative_errors[i_max])
    max_rel_error_iteration.append(max_rel_error)
    # print(f"Largest error @ {i_max}: {max_rel_error:.5}")

    # 4. If relative error is too large, then solve primal and dual FOM on
    # time step with largest error
    if max_rel_error <= REL_ERROR_TOL:
        print(f"  INFO: Terminating with max error: {max_rel_error:.5} (TOL = {REL_ERROR_TOL})")
        break
    else:
        # 4a) Solve primal FOM at i_max and enrich primal POD
        primal_snapshot = solve_primal_FOM_timestep(
            project_vector(Y_ROM[:, i_max], POD_primal_dict["POD"]),
            RHS[:, i_max + 1],
        )

        if PLOT:
            u = Function(V)
            u.vector().set_local(primal_snapshot)
            plot(u)
            plt.title("Primal FOM solution")
            plt.show()

        # update POD basis
        POD_primal_dict = iPOD(
            **POD_primal_dict,
            snapshot=primal_snapshot,
            bunch_size=BUNCH_SIZE,
            energy_content=ENERGY_CONTENT,
        )

        # update reduced matrices
        RHS_reduced_primal = np.dot(POD_primal_dict["POD"].T, RHS)
        reduced_system_matrix = reduce_matrix(system_matrix, POD_primal_dict["POD"], use_petsc=True)
        reduced_rhs_matrix = reduce_matrix(rhs_matrix, POD_primal_dict["POD"], use_petsc=True)

        # 4b) Solve dual FOM at i_max and enrich dual POD
        dual_snapshot = solve_dual_FOM_timestep(
            primal_snapshot,
            project_vector(Y_ROM_dual[:, i_max + 1], POD_dual_dict["POD"]),
        )

        if PLOT:
            z = Function(V)
            z.vector().set_local(dual_snapshot)
            plot(z)
            plt.title("Dual FOM solution")
            plt.show()

        # update POD basis
        POD_dual_dict = iPOD(
            **POD_dual_dict,
            snapshot=dual_snapshot,
            bunch_size=BUNCH_SIZE,
            energy_content=DUAL_ENERGY_CONTENT,
        )

        # update reduced matrices
        reduced_dual_system_matrix = reduce_matrix(dual_system_matrix, POD_dual_dict["POD"])
        reduced_dual_rhs_matrix = reduce_matrix(dual_rhs_matrix, POD_dual_dict["POD"])

        # update reduced matrices for error computations
        RHS_reduced_dual = np.dot(POD_dual_dict["POD"].T, RHS)
        # dualprim := dual - primal -> left multiply with dual POD transpose
        # and right multiply with primal POD
        dualprim_reduced_system_matrix = reduce_matrix(
            system_matrix, POD_dual_dict["POD"], POD_primal_dict["POD"]
        )
        dualprim_reduced_rhs_matrix = reduce_matrix(
            rhs_matrix, POD_dual_dict["POD"], POD_primal_dict["POD"]
        )

        iteration += 1

execution_time_ROM = time.time() - start_execution
print(f"Done [{execution_time_ROM:.2f} s]")

plt.plot(max_rel_error_iteration)
plt.grid()
plt.xlabel("iteration", fontsize=16)
plt.ylabel("max rel error", fontsize=16)
if PLOT:
    plt.show()
else:
    plt.savefig("max_rel_error.png")
    plt.clf()
    # plt.close(fig)

plt.title("Functional values")
plt.plot(functional_values, label="ROM")
plt.plot(functional_values_FOM, label="FOM")
plt.legend()
if PLOT:
    plt.show()
else:
    plt.savefig("functional_values.png")
    plt.clf()
    # plt.close(fig)

plt.title("Error")
plt.plot(functional_values_FOM - functional_values, label="true error")
plt.plot(errors, label="estimated error")
plt.legend()
if PLOT:
    plt.show()
else:
    plt.savefig("error.png")
    plt.clf()
    # plt.close(fig)

fig, ax = plt.subplots()
ax.set_title("Relative error [in %]")
ax.axhline(y=100.0 * REL_ERROR_TOL, color="r", label="TOL", linestyle="--")
ax.plot(
    100.0 * np.abs((functional_values_FOM - functional_values) / (functional_values_FOM + 1e-20)),
    label="true error",
)
ax.plot(100.0 * np.abs(errors / (errors + functional_values + 1e-20)), label="estimated error")
ax.legend()
if PLOT:
    plt.show()
else:
    plt.savefig("relative_error.png")
    plt.clf()
    plt.close(fig)

print("\n\nResults:")
print(f"J(u_h):            {np.sum(functional_values_FOM)}")
print(f"J(u_N):            {np.sum(functional_values)}")
print(f"True error:        {np.sum(functional_values_FOM - functional_values)}")
print(f"Estimated error:   {np.sum(errors)}")
print(
    f"Effectivity index: {np.abs(np.sum(errors)/np.sum(functional_values_FOM - functional_values))}"
)
print(
    f"Indicator index:   {np.sum(np.abs(errors))/np.sum(np.abs(functional_values_FOM - functional_values))}"
)

print(f"FOM time:         {execution_time_FOM:.2f} s")
print(f"ROM time:         {execution_time_ROM:.2f} s")
# NOTE: actual speed up can also be better than the maximal speedup, since
# we compute the goal functional for both FOM and ROM; it is however more
# costly to compute the goal functional for the FOM
# 2 * iterations = number FOM solves (primal and dual); Y.shape[1] - 1 =
# number of timesteps
print(
    f"Speedup: act/max: {execution_time_FOM/execution_time_ROM:.3f} / {(Y.shape[1] - 1)/(2*iteration):.3f}"
)
print(f"Size ROM:         {POD_primal_dict['POD'].shape[1]}")
print(f"Size ROM - dual:  {POD_dual_dict['POD'].shape[1]}")
print(f"FOM solves:       {iteration} / {Y.shape[1] - 1}")

# Plotting
print("Plotting...")
u_FOM = Function(V)
u_ROM = Function(V)
u_diff = Function(V)

u_max = np.max(np.max(Y))
u_min = np.min(np.min(Y))

# project Y_ROM into FOM space
Y_ROM_projected = np.dot(POD_primal_dict["POD"], Y_ROM)

diff_max = np.max(np.max(Y - Y_ROM_projected))
diff_min = np.min(np.min(Y - Y_ROM_projected))

if not os.path.exists("images"):
    os.makedirs("images")

size_colorbar = 0.9
pad_space = 0.2
skip_frames = 5
for i in range(0, Y.shape[1], skip_frames):
    fig, axes = plt.subplots(1, 3, figsize=(10, 4))

    u_FOM.vector().set_local(Y[:, i])
    u_ROM.vector().set_local(Y_ROM_projected[:, i])
    u_diff.vector().set_local(Y[:, i] - Y_ROM_projected[:, i])

    plt.subplot(1, 3, 1)
    c = plot(u_FOM, title="Velocity - FOM", vmin=u_min, vmax=u_max)
    cbar = plt.colorbar(
        c,
        orientation="horizontal",
        ticks=MaxNLocator(nbins=3),
        format=FormatStrFormatter("%.2f"),
        pad=pad_space,
        shrink=size_colorbar,
    )
    cbar.mappable.set_clim(u_min, u_max)

    plt.subplot(1, 3, 2)
    c = plot(u_ROM, title="Velocity - ROM", vmin=u_min, vmax=u_max)
    cbar = plt.colorbar(
        c,
        orientation="horizontal",
        ticks=MaxNLocator(nbins=3),
        format=FormatStrFormatter("%.2f"),
        pad=pad_space,
        shrink=size_colorbar,
    )
    cbar.mappable.set_clim(u_min, u_max)

    plt.subplot(1, 3, 3)
    c = plot(u_diff, title="Velocity - Difference", vmin=diff_min, vmax=diff_max)
    cbar = plt.colorbar(
        c,
        orientation="horizontal",
        ticks=MaxNLocator(nbins=3),
        format=FormatStrFormatter("%.4f"),
        pad=pad_space,
        shrink=size_colorbar,
    )
    cbar.mappable.set_clim(diff_min, diff_max)

    plt.tight_layout()

    plt.savefig(f"images/solution{i:05}.png")
    plt.clf()
    plt.close(fig)

# generate video
if os.path.exists("out.mp4"):
    os.remove("out.mp4")

# call ffmpeg to create mp4 from pngs
os.system(
    "ffmpeg -framerate 10 -pattern_type glob -i 'images/*.png' -c:v libx264 -r 30 -pix_fmt yuv420p out.mp4 > /dev/null 2>&1"
)
print("Done.")
